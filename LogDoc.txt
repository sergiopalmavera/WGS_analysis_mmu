mportant #
#############

- I started (quite late I must say) this log book to write down the train of thought I took to solve certain issues. 
- I used to do this on my physical notebook by pen, but since the corona break started Ive been trying to avoid touching objects as much as possible. 
- This document is a dump of mostly errors and how I solve them. Also it is sort of a diary to list the stuff I did on any given day. I guess this might be helpfull for the future.


##################
# Mon 16.03.2020 # 
##################


# GenotypeGVCFs threw an error while processing chr2:

10:08:46.698 INFO  ProgressMeter -          2:153971859           5725.0            1354740000         236636.3
10:08:56.783 INFO  ProgressMeter -          2:154007859           5725.2            1354776000         236635.7
10:09:00.920 INFO  GenotypeGVCFs - Shutting down engine
[15. Mâ–’rz 2020 10:09:01 MEZ] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 5,725.25 minutes.
Runtime.totalMemory()=5758779392
htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 1354789544: there are 120 genotypes while the header requires that 149 genotypes be present for all records at 2:154021236

# At 2:154021236 there are 120 genotypes instead of 149 (150 minus the drop out sample).

# What should I do next?

- Extract the region around the problematic line (this takes a while).

- Post a question on the gatk forum

- After dropout sample is done being processed by HaplotypeCaller and while I wait for an forum-answer, I will use "ConsolidateGVCFs" instead of "CombineGVCFs" (https://gatk.broadinstitute.org/hc/en-us/articles/360035889971?flash_digest=cab2d85e4c16398547fbdae6825867894ff59cf7)

# By the way:
- The number of sites in the cohort.g.vcf file (after CombineGVCFs) is 200,823,577 ... 200M variants!!

- The total number of short variants in dbSNPs is 83,761,978 (http://www.ensembl.org/Mus_musculus/Info/Annotation)

- The size of the file is 4T

- The dropout sample was resequenced and is currently under HaplotypeCaller. Either way I was not gonna move on from GenotypeGVCFs had it been succesfull.

##################
# Tue 17.03.2020 #
##################

# Checkin the problematic line in multi-vcf file after CombineGVCFs:
- there were indeed only 120 samples for that snp, all of them were "./.", and the site had "<NON_REF>" as the alternative allele. 
- The previous site (2       154021235) had ./. for every sample, but there were 149 samples, as expected. Alternative allele was defined as "<NON_REF>".
- I posted a question on the gatk forum: https://gatk.broadinstitute.org/hc/en-us/community/posts/360059094892-Less-samples-than-expected-due-to-malformed-VCF
- While I wait for an answer I will run ConsolidateGVCFs on chr2. 
- according to gatk, the tool GenomicsDB is stable as of v4.0.8.0, but I am using gatk 4.0.6.0, so I will switch to the latest version v1.5.0 from now on. Also the new version includes: "A new version of GenomicsDB that fixes many frequently-reported issues"
- I only ran GenomicsDB on chr2, because it was giving trouble.

##################
# Mon 23.03.2020 #
##################

* Until the creation of individual GVCFss files (HaplotypeCaller) I was using gatk-4.0.6.0. It was done this way because is the GATK version I used for the original WGS batches (60 samples, 20x) and to be consistent with the new batch of WGS data in 2020 (90 samples, ~5x). Thus, all sample-gvcfs (150) were produced with exactly the same pipeline.

* Since the step CombineGVCFs was not succesful due to an issue in gatk-4.0.6.0 (see answer to my post indicated above). I opted to switch to ConsolidateGVCFs instead (faster) and to use the newest GATK version (gatk-4.1.5.0 -> more stable). 

* After completion of ConsolidateGVCFs I continued using the same gatk version. However, an issue was indicated by GenotypeGVCFs alerting that one of the INFO annotations was deprecated (rms-mapping-quality), which was produced by an older version of GATK. To "updated" this annotation I would have to re-run HaplotypeCaller on all 150 samples, which is not feasable due to time-constrains. Also, deprecated does not mean it is wrong to use. In order to solve this conflict, I added the flag '--allow-old-rms-mapping-quality-annotation-data' and GenotypeGVCFs continued without errors.

* Also, to see if the problem with CombineGVCFs was actually due to using an older version of GATK, I redid the step accordingly.

#################
# Mon 30.03.202 #
#################

* ConsolidateGVCFs has been taking several days to complete (chr1-chr12, chrX). It's been already 10 days.
* When I saw it was taking too long, I tried and run CombineGVCFs again and in completed two days ago. So today I started GenotypeGVCFs on that cohort gvcf. However, this is the second time I try, but with latest GATK version (see script) (the time before I used and older version of GATK4 and I was suggested to repeat with newest version).
* ConsolidateGVF was left running anayway. 
* Apparently the N+1 solution from GATK3 is no longer applicable for GATK4: http://seqanswers.com/forums/showthread.php?t=89241 AND https://gatkforums.broadinstitute.org/gatk/discussion/23921/how-to-combine-the-interval-after-genomicsdbimport#latest

##################
# Thu 02.04.2020 #
##################

* GenotypeGVCFs finished running on the new combined VCF. This time both CombineGVCFs and GenotypeGVCFs were applied using the latest GATK version.

* Again, GenotypeGVCFs failed around the same region: line number 1354795748 (there are 28 genotypes while the header requires that 149 genotypes)

* Before, using and older version of GATK4 it failed at: line number 1354789544 (there are 120 genotypes while the header requires that 149 genotypes)

* So it appeared that first error was fixed (line 1354789544 appears earlier than line 1354795748).

* ConsolidateGVCFs is still running for the last 2 weeks (it started between March 17-18) on chrs 1-11,X. This is the alternative plan, in case that CombineGVCFs-GenotypeGVCFs did not work, which was the case.

* So what to do now for CombineGVCFs-GenotypeGVCFs?
	* The Run consisted of 149 files anyway, 1 file is missing so CombineGVCFs would've had to be run again, had GenotypeGVCFs worked.
	* Re-run CombineGVCFs with the 150 files.
	* Using the older GVCFs (with 149 files) see if sites with incomplete number of genotypess can be removed. Then run GenotypeGVCs. All this under an EXP directory
	* Remove incomplete lines from new combined VCF and run GenotypeGVCFs, if solution above solved the problem.
* What about ConsolidateGVCFs with genomicsdbimport?
	* chr1 to chr11 and chrX are still running. Probably too much to handle. 
	* An approach is to split a chr by intervals as mentions in this threads:
		* https://gatkforums.broadinstitute.org/gatk/discussion/12443/genomicsdbimport-run-slowly-with-multiple-samples
	* Run only chr1 on a new directory "batches123_01_ConsolidateGVFs_by_intervals" using latest gatk version: 4.1.5.0. If done in a few days, proceed with rest of chromosomes (except chr 13 - 19. Those are done).
	* I split chr1 into unmasked intervals according to GATK (see link above). Applying the method here using ucsc utilities: https://www.biostars.org/p/320184/
	* Note on BED files and GATK: BED files are 0-based. GATK tools recognise this if the file is .bed.

##################
# Fir 03.04.2020 #
##################

* The approach of splitting by intervals worked apparently. However, for those intervals that were too large, the jobs were not completed overnight.

* In order to increase the speed of this analysis, I need jobs to complete overnight, so I had to split those intervals >5Mb into intervals of max 5Mb. I did this using bedtools again with the function make windows.

* I also cancelled all GenomicsDBImport jobs running for chr1 in linu4 from last night.

* I will repeat the analysis for chr1 with this new approach (cosolidate by intervals with no interval larger than 5Mb).

* Left that runnin, once it's done, go on with chr2. Then move on with both chrs to GenotypeGVCFs. Once done, scale to remaining chrs (3-12,X).

* Checking the results of removing records with at least one missing phenotype, the following error came out:

	[E::vcf_parse_format] Number of columns at 2:154027440 does not match the number of samples (28 vs 149)
	Error: VCF parse error

* This occurs at a similar location as the previous errors towards the end of chromsome 2 (SN:2    LN:182113224). The associated directory '/batches123_01_CombineGVFs/EXP' was removed.
  
##################
# Sat 04.04.2020 #
##################

* Jobs for chr1 and chr2 in order to apply GenomicDBImport (ConsolidateGVCFs) by intervals were completed almost overnight (some were completed during this morning).

* Recall that each interval corresponds to a region between NNNN (masked) regions, including the beginning and end of the chr, of course. However, if an interval was >5Mb, it was split into smaller intervals of max 5Mb. 

* Today I submitted the jobs for those two chrs applying GenotypeGVCFs by intervals, using the same intervals as for GenomicsDBImport. 

* My main concern with this approach is that indels could be disrupted once the genome is split. However, I don't see another way to do this at the moment.

##################
# Sun 05.04.2020 #
##################

* I concatenated all interval-parts for each chr1 and chr2 after GenotypeGVCFs finished running on those samples. For concatenating I used bcftools 1.9, since GATK4 does not have that functionality built in anymore. The process was concluded with no trouble, so now chr1 and chr2 are completely joint-genotyped, although it might require sorting later.

* I am not sure what would happen to indels now that chrs were devided into smaller intervals. I need to ask around about that.

* I submitted the jobs for Consolidating gvcfs from chr 3,4,5.

* I killed the ongoing jobs for GenomicsDBImport for chrs 2-11,X since the by-interval methods seems to work fine.

* I checked the previously problematic chr2 and it had warnings about some sites having too many genotypes, apparently not a big deal:
	* https://gatkforums.broadinstitute.org/gatk/discussion/7548/does-my-genotypegvcfs-progress-report-indicate-problems-with-the-results
	* https://github.com/broadinstitute/gatk/issues/2689
	* https://gatkforums.broadinstitute.org/gatk/discussion/11873/genotypegvcfs-how-to-bump-up-the-number-of-alleles-in-the-combined-vcf-record
	* https://gatkforums.broadinstitute.org/gatk/discussion/24457/tiledb-gzip-error-when-using-genotypegvcfs-on-genomicsdb











